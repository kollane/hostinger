# Docker Image Optimeerimise 5 EesmÃ¤rki

Docker image optimeerimise peamised eesmÃ¤rgid tootmiskÃµlbuliku rakenduse jaoks.

---

## 1ï¸âƒ£ Kiire Arendusprotsess - Layer Caching

### Probleem: Aeglane rebuild

**Mitteoptimeeritud Dockerfile:**
```dockerfile
FROM node:22-slim
WORKDIR /app

# âŒ PROBLEEM: Kopeerin koodi enne sÃµltuvusi
COPY . .                    # â† Muudad Ã¼ht JS faili â†’ see kiht muutub
RUN npm install             # â† npm install kÃ¤ib ALATI uuesti! (30-60s)

CMD ["node", "server.js"]
```

**Miks see on aeglane?**
- Docker salvestab iga kÃ¤su (RUN, COPY, etc) eraldi **kihina (layer)**
- Docker kasutab vahemÃ¤lu (cache): kui kiht ei muutu, kasutatakse cached versiooni
- **Aga:** kui `COPY . .` muutub (muutsid koodi), siis **kÃµik jÃ¤rgnevad kihid** rebuilditakse!
- Tulemus: npm install kÃ¤ib IGAL build'il uuesti, isegi kui package.json ei muutunud

### Lahendus: SÃµltuvused eraldi kihina

**Optimeeritud Dockerfile:**
```dockerfile
FROM node:22-slim
WORKDIR /app

# âœ… LAHENDUS: Kopeeri sÃµltuvuste failid ENNE koodi
COPY package*.json ./       # â† Muutub HARVA (kiht cached)
RUN npm install             # â† Cached! Rebuild 5 sekundit

COPY . .                    # â† Muutub TIHTI, aga kiire (ei kÃ¤ivita npm install uuesti)

CMD ["node", "server.js"]
```

**Miks see on kiire?**
- package.json muutub harva (ainult kui lisad/uuendad sÃµltuvusi)
- npm install kiht on **cached** â†’ ei kÃ¤ivita uuesti
- Muudad lÃ¤htekoodi (server.js) â†’ ainult COPY . . kÃ¤ib uuesti (millisekund!)

### MÃµÃµdetav mÃµju

**Esimene build (ilma cache'ita):**
- Mitteoptimeeritud: 45 sekundit
- Optimeeritud: 50 sekundit (+5s, sest 2 COPY kÃ¤sku)

**Rebuild (muutsid server.js):**
- Mitteoptimeeritud: 45 sekundit (npm install uuesti!)
- Optimeeritud: 2 sekundit (ainult COPY . .)

**Tulemus:** Arendaja muudab koodi â†’ rebuild **95% kiirem** (45s â†’ 2s)

### Praktiline nÃ¤ide

**TÃ¼Ã¼piline arendusprotsess:**
1. Muuda koodi (nt. lisa endpoint)
2. Rebuild Docker image
3. KÃ¤ivita konteiner
4. Testi
5. Korda 1-4 (10-50 korda pÃ¤evas!)

**Ilma layer caching'uta:** 10 rebuild Ã— 45s = **7.5 minutit ootamist**
**Layer caching'uga:** 10 rebuild Ã— 2s = **20 sekundit ootamist**

**Ajakasu pÃ¤evas:** 7-8 minutit (Ã— 5 pÃ¤eva = 35-40 min nÃ¤dalas!)

---

## 2ï¸âƒ£ VÃ¤iksem Image Suurus - Multi-stage Build

### Probleem: Liiga suur runtime image

**Mitteoptimeeritud Dockerfile (Java):**
```dockerfile
FROM gradle:8-jdk21-alpine
WORKDIR /app

# Kopeeri kÃµik (source code + build tools)
COPY . .

# Ehita JAR
RUN gradle bootJar

# KÃ¤ivita JAR
CMD ["java", "-jar", "build/libs/app.jar"]
```

**Miks see on suur?**
- Runtime image sisaldab:
  - âœ… JRE (Java Runtime Environment) - VAJALIK (200MB)
  - âŒ JDK (Java Development Kit) - EI OLE VAJALIK (400MB)
  - âŒ Gradle - EI OLE VAJALIK (150MB)
  - âŒ Source code - EI OLE VAJALIK (50MB)
- **Kokku:** ~800MB image, millest ainult 25% on runtime'is vajalik!

**Turvarisk:**
- Build tools (gradle, javac) runtime'is â†’ vÃµimalik kompileerida pahavara
- Source code runtime'is â†’ intellektuaalne omand leak'ib

### Lahendus: Multi-stage Build

**Optimeeritud Dockerfile (Java):**
```dockerfile
# syntax=docker/dockerfile:1.4

# =====================================
# STAGE 1: BUILD (JDK + Gradle)
# =====================================
FROM gradle:8-jdk21-alpine AS builder
WORKDIR /app

# Kopeeri Gradle failid (dependency caching)
COPY build.gradle settings.gradle ./
COPY gradle ./gradle

# Lae sÃµltuvused (cached eraldi kihina)
RUN gradle dependencies --no-daemon

# Kopeeri source code ja ehita JAR
COPY src ./src
RUN gradle bootJar --no-daemon

# =====================================
# STAGE 2: RUNTIME (ainult JRE)
# =====================================
FROM eclipse-temurin:21-jre-alpine
WORKDIR /app

# Kopeeri AINULT JAR builder stage'ist
COPY --from=builder /app/build/libs/*.jar app.jar

# KÃ¤ivita JAR
CMD ["java", "-jar", "app.jar"]
```

**Miks see on vÃ¤ike?**
- **Stage 1 (builder):** 800MB - sisaldab JDK + Gradle + source
  - Kasutatakse AINULT build'imiseks
  - Ei jÃ¤Ã¤ lÃµplikku image'isse!
- **Stage 2 (runtime):** 250MB - sisaldab AINULT JRE + JAR
  - Ainult see stage eksporditakse
  - Pole build tools'e ega source code'i

### MÃµÃµdetav mÃµju

**Image suurused:**
- Mitteoptimeeritud (single-stage): 800MB
- Optimeeritud (multi-stage): 250MB
- **VÃ¤hendamine:** 550MB (-69%)

**Deployment mÃµju (Kubernetes 3 replicat):**
- Mitteoptimeeritud: 3 Ã— 800MB = 2.4GB allalaadida
- Optimeeritud: 3 Ã— 250MB = 750MB allalaadida
- **Aeg sÃ¤Ã¤stetud (100Mbps vÃµrk):** ~3 minutit

**KÃµvaketas (10 microservice'it):**
- Mitteoptimeeritud: 10 Ã— 800MB = 8GB
- Optimeeritud: 10 Ã— 250MB = 2.5GB
- **Kokkuhoid:** 5.5GB (vÃ¤hem layer cache ruumi vaja)

### Node.js vs Java multi-stage erinevus

**Node.js:**
```dockerfile
# Stage 1: Dependencies
FROM node:22-slim AS dependencies
COPY package*.json ./
RUN npm ci --only=production

# Stage 2: Runtime (sama base image!)
FROM node:22-slim
COPY --from=dependencies /app/node_modules ./node_modules
COPY . .
```

**Miks Node.js multi-stage ei vÃ¤henda suurust?**
- MÃµlemad stage'id kasutavad SAMA base image'it (node:22-slim)
- Suuruse vÃ¤hendamine: ~0% (mÃµlemad ~305MB)
- **Aga:** Kihtide vahemÃ¤lu on PAREM (dependencies eraldi kihis)

**Java vs Node.js:**
- Java: JDK (800MB) â†’ JRE (250MB) = **69% vÃ¤iksem** âœ…
- Node.js: node:22-slim â†’ node:22-slim = **0% vÃ¤iksem** âš ï¸

**Ã•ppetund:** Multi-stage build annab Node.js'ile **kiiremad rebuildid**, aga mitte vÃ¤iksemat image'it

---

## 3ï¸âƒ£ Turvalisus - Non-root User + Health Checks

### Probleem: Rakendus tÃ¶Ã¶tab root'ina

**Mitteoptimeeritud Dockerfile:**
```dockerfile
FROM node:22-slim
WORKDIR /app

COPY package*.json ./
RUN npm install

COPY . .

CMD ["node", "server.js"]
# â†‘ TÃ¶Ã¶tab root kasutajana (UID 0)!
```

**Miks see on ohtlik?**
- Konteiner tÃ¶Ã¶tab **root** kasutajana (UID 0)
- Kui rÃ¼ndaja saab konteineri Ã¼le:
  - âŒ VÃµib kirjutada sÃ¼steemifaile host masinas (kui volume mount on)
  - âŒ VÃµib escalada Ãµigusi (privilege escalation)
  - âŒ VÃµib kompromiteerida teisi konteinereid
- **OWASP Top 10:** "Security Misconfiguration"

### Lahendus 1: Non-root User

**Optimeeritud Dockerfile (Debian/Ubuntu base):**
```dockerfile
FROM node:22-slim
WORKDIR /app

# Kopeeri ja installi sÃµltuvused (veel root'ina, ok)
COPY package*.json ./
RUN npm ci --only=production

# Kopeeri rakenduse kood
COPY . .

# âœ… LOO MITTE-JUURKASUTAJA
RUN groupadd -g 1001 nodejs && \
    useradd -r -u 1001 -g nodejs nodejs

# âœ… MUUDA FAILIDE OMANIK
RUN chown -R nodejs:nodejs /app

# âœ… LÃœLITU MITTE-JUURKASUTAJALE
USER nodejs:nodejs

EXPOSE 3000
CMD ["node", "server.js"]
```

**Alpine Linux variant:**
```dockerfile
FROM node:22-alpine
WORKDIR /app

COPY package*.json ./
RUN npm ci --only=production

COPY . .

# âœ… Alpine kasutab adduser/addgroup
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nodejs -u 1001 -G nodejs

RUN chown -R nodejs:nodejs /app

USER nodejs:nodejs

EXPOSE 3000
CMD ["node", "server.js"]
```

**Miks see on turvalisem?**
- Rakendus tÃ¶Ã¶tab UID 1001 (mitte-root)
- Ei saa kirjutada sÃ¼steemifaile
- VÃ¤iksem attack surface

### Lahendus 2: Health Check

**Ilma health check'ita:**
```dockerfile
FROM node:22-slim
WORKDIR /app

# ... install dependencies, copy code ...

CMD ["node", "server.js"]
# âŒ Docker ei tea, kas rakendus tÃ¶Ã¶tab korrektselt!
```

**Probleem:**
- Konteiner on "Up", aga rakendus ei vasta (hang/deadlock)
- Docker Compose/Kubernetes ei tea, et midagi on valesti
- Liiklus suunatakse vigasesse konteinerisse

**Health check'iga:**
```dockerfile
FROM node:22-slim
WORKDIR /app

COPY package*.json ./
RUN npm ci --only=production

COPY . .

RUN groupadd -g 1001 nodejs && \
    useradd -r -u 1001 -g nodejs nodejs
RUN chown -R nodejs:nodejs /app

USER nodejs:nodejs

EXPOSE 3000

# âœ… TERVISEKONTROLL
HEALTHCHECK --interval=30s \      # Kontrolli iga 30 sekundi tagant
            --timeout=3s \         # Maksimaalne vastuse aeg
            --start-period=10s \   # Lubab 10s startup aega
            --retries=3 \          # 3 ebaÃµnnestumist â†’ unhealthy
  CMD node healthcheck.js || exit 1

CMD ["node", "server.js"]
```

**healthcheck.js fail:**
```javascript
const http = require('http');

const options = {
  host: 'localhost',
  port: 3000,
  path: '/health',
  timeout: 2000
};

const req = http.request(options, (res) => {
  if (res.statusCode === 200) {
    process.exit(0);  // Healthy
  } else {
    process.exit(1);  // Unhealthy
  }
});

req.on('error', () => process.exit(1));  // Unhealthy
req.end();
```

### MÃµÃµdetav mÃµju

**Turvalisus:**
- Root exploit vÃµimalus: 80% â†’ 20% (limited user permissions)
- Container escape: Raskem (pole root Ãµigusi)

**Monitooring:**
- Docker Compose:
  ```bash
  docker ps
  # STATUS
  # Up (healthy)  â† NÃ¤ed kohe, et rakendus tÃ¶Ã¶tab!
  ```
- Kubernetes: Readiness/Liveness probe kasutab HEALTHCHECK tulemust
- Automaatne restart: Kui 3 healthcheck ebaÃµnnestub â†’ restart

**NÃ¤ide stsenaarium:**
1. Rakendus hangub (memory leak, deadlock)
2. HEALTHCHECK ebaÃµnnestub 3 korda (30s Ã— 3 = 90s)
3. Docker restart'ib konteineri automaatselt
4. **Downtime:** 90s (ilma health check'ita: âˆ)

---

## 4ï¸âƒ£ Portaabelsus - Corporate Proxy Tugi

### Probleem: Dockerfile ei tÃ¶Ã¶ta corporate vÃµrgus

**Mitteoptimeeritud Dockerfile:**
```dockerfile
FROM node:22-slim
WORKDIR /app

COPY package*.json ./
RUN npm install  # âŒ EBAÃ•NNESTUB corporate vÃµrgus!
# Error: getaddrinfo ENOTFOUND registry.npmjs.org

COPY . .
CMD ["node", "server.js"]
```

**Miks see ebaÃµnnestub?**
- Corporate vÃµrk (nt. Intel, bank, government) blokeerib otsese interneti ligipÃ¤Ã¤su
- KÃµik HTTP/HTTPS pÃ¤ringud peavad minema lÃ¤bi proksi serveri (nt. `http://proxy-chain.intel.com:911`)
- npm install ei tea proksi aadressist â†’ ei saa packages'eid alla laadida

**Vale lahendus: Hardcoded proxy**
```dockerfile
FROM node:22-slim
WORKDIR /app

# âŒ VALE: Hardcoded proxy
ENV HTTP_PROXY=http://proxy-chain.intel.com:911
ENV HTTPS_PROXY=http://proxy-chain.intel.com:912

COPY package*.json ./
RUN npm install

COPY . .
CMD ["node", "server.js"]
```

**Miks see on halb?**
- âœ… TÃ¶Ã¶tab Intel vÃµrgus
- âŒ **EI tÃ¶Ã¶ta AWS/GCP/Azure** (pole proxy'd!)
- âŒ Proxy **leak'ib runtime'i** â†’ rakendus proovib kasutada Intel proxy'd production'is
- âŒ **Security risk:** Proxy credentials vÃµivad olla URL'is (`http://user:pass@proxy:911`)

### Lahendus: ARG-pÃµhine proxy (portaabel)

**Optimeeritud Dockerfile:**
```dockerfile
# syntax=docker/dockerfile:1.4

# âœ… ARG deklaratsioonid ENNE FROM (globaalsed)
ARG HTTP_PROXY=""
ARG HTTPS_PROXY=""
ARG NO_PROXY=""

# Stage 1: Dependencies
FROM node:22-slim AS dependencies

# âœ… ENV AINULT selles stage'is
ENV HTTP_PROXY=${HTTP_PROXY} \
    HTTPS_PROXY=${HTTPS_PROXY} \
    NO_PROXY=${NO_PROXY}

WORKDIR /app

COPY package*.json ./
RUN npm ci --only=production  # Kasutab HTTP_PROXY, kui mÃ¤Ã¤ratud

# Stage 2: Runtime
FROM node:22-slim
WORKDIR /app

# âœ… PROXY EI OLE SIIN! Uus FROM nullib ENV muutujad
COPY --from=dependencies /app/node_modules ./node_modules
COPY . .

RUN groupadd -g 1001 nodejs && \
    useradd -r -u 1001 -g nodejs nodejs
RUN chown -R nodejs:nodejs /app

USER nodejs:nodejs

EXPOSE 3000
CMD ["node", "server.js"]
```

**Kuidas kasutada?**

**Intel vÃµrgus (proksi keskkonnas):**
```bash
docker build \
  --build-arg HTTP_PROXY=http://proxy-chain.intel.com:911 \
  --build-arg HTTPS_PROXY=http://proxy-chain.intel.com:912 \
  -t user-service:1.0 \
  .
```

**AWS/GCP/Azure (ilma proksita):**
```bash
docker build -t user-service:1.0 .
# ARG vaikevÃ¤Ã¤rtused on "" â†’ tÃ¶Ã¶tab ilma proksita!
```

**Miks see on parem?**
- âœ… **Portaabel:** Sama Dockerfile tÃ¶Ã¶tab mÃµlemas keskkonnas
- âœ… **Turvaline:** Proxy EI leak runtime'i (multi-stage eraldab)
- âœ… **Production-ready:** Image tÃ¶Ã¶tab AWS/GCP ilma Intel proksita

### Java/Gradle eripÃ¤ra

**Gradle EI kasuta HTTP_PROXY otse!**

**Vale lÃ¤henemine:**
```dockerfile
ARG HTTP_PROXY=""
ENV HTTP_PROXY=${HTTP_PROXY}

RUN gradle bootJar  # âŒ Gradle ignoorib HTTP_PROXY!
```

**Ã•ige lÃ¤henemine (GRADLE_OPTS):**
```dockerfile
# syntax=docker/dockerfile:1.4

ARG HTTP_PROXY=""

FROM gradle:8-jdk21-alpine AS builder
ENV HTTP_PROXY=${HTTP_PROXY}

WORKDIR /app
COPY build.gradle settings.gradle ./

# âœ… Gradle vajab GRADLE_OPTS
RUN if [ -n "$HTTP_PROXY" ]; then \
        PROXY_HOST=$(echo "$HTTP_PROXY" | sed -e 's|http://||' -e 's|:[0-9]*$||'); \
        PROXY_PORT=$(echo "$HTTP_PROXY" | grep -oE '[0-9]+$'); \
        export GRADLE_OPTS="-Dhttp.proxyHost=$PROXY_HOST -Dhttp.proxyPort=$PROXY_PORT"; \
        gradle dependencies --no-daemon; \
    else \
        gradle dependencies --no-daemon; \
    fi

COPY src ./src
RUN gradle bootJar --no-daemon

FROM eclipse-temurin:21-jre-alpine
# Runtime on clean (proxy pole siin)
COPY --from=builder /app/build/libs/*.jar app.jar
CMD ["java", "-jar", "app.jar"]
```

### MÃµÃµdetav mÃµju

**Portaabelsus:**
- Sama Dockerfile tÃ¶Ã¶tab 3 keskkonnas:
  1. âœ… Intel corporate vÃµrk (proxy)
  2. âœ… AWS/GCP/Azure (ilma proksita)
  3. âœ… Arendaja masinas (ilma proksita)

**Deployment:**
- Ilma ARG proxy'ta: 2 erinevat Dockerfile'i (Intel vs Cloud)
- ARG proxy'ga: 1 Dockerfile (portaabel!)

**Turvarisk vÃ¤henemine:**
- Proxy leak runtime'i: 0% (multi-stage eraldab)
- Credentials leak: 0% (ARG on build-time ainult)

---

## 5ï¸âƒ£ CI/CD Kiirus - Reproducible Builds

### Probleem: Mittedeterministlikud build'id

**Mitteoptimeeritud Dockerfile:**
```dockerfile
FROM node:22-slim
WORKDIR /app

COPY package.json ./  # âŒ Ainult package.json, pole package-lock.json!
RUN npm install       # âŒ Installib UUSIMAD versioonid!

COPY . .
CMD ["node", "server.js"]
```

**Probleem:**
- `npm install` (ilma lock file'ita) installib UUSIMAD sÃµltuvuste versioonid
- **TÃ¤na:** express@4.18.2
- **Homme:** express@4.18.3 (uus patch release)
- **Tulemus:** Eri build'id annavad ERINEVAID images'eid!

**Miks see on halb?**
- âŒ **Development vs Production:** Image development'is â‰  image production'is
- âŒ **Debugging:** "TÃ¶Ã¶tab minu masinas, aga mitte production'is"
- âŒ **Rollback:** Rollback versioonile v1.2.3 vÃµib tuua ERINEVAID sÃµltuvusi
- âŒ **CI/CD:** Cache ei tÃ¶Ã¶ta (sÃµltuvused muutuvad IGAL build'il)

### Lahendus 1: package-lock.json (Node.js)

**Optimeeritud Dockerfile:**
```dockerfile
FROM node:22-slim
WORKDIR /app

# âœ… Kopeeri MÃ•LEMAD failid
COPY package*.json ./

# âœ… npm ci (mitte npm install!)
RUN npm ci --only=production

COPY . .

USER nodejs:nodejs
CMD ["node", "server.js"]
```

**npm ci vs npm install:**

| Aspekt | npm install | npm ci |
|--------|-------------|--------|
| Kasutab package-lock.json? | âš ï¸ Jah, aga uuendab seda | âœ… Jah, RANGELT |
| Deterministlik? | âŒ Ei (installib uuemaid) | âœ… Jah (tÃ¤pselt package-lock) |
| Kiirem CI/CD's? | âŒ Aeglane (kontrollib updates) | âœ… Kiire (skip updates) |
| Production'ile? | âŒ EI SOOVITATUD | âœ… SOOVITATAV |

**npm ci garanteerib:**
- TÃ¤pselt SAMA sÃµltuvused igal build'il
- Sama express versioon (4.18.2), mitte uuem (4.18.3)
- Reproducible builds

### Lahendus 2: Gradle Lock File (Java)

**Gradle lockfile genereerimise:**
```bash
# Genereeri gradle.lockfile
gradle dependencies --write-locks
```

**build.gradle konfiguratsioon:**
```gradle
dependencyLocking {
    lockAllConfigurations()
}
```

**Dockerfile:**
```dockerfile
FROM gradle:8-jdk21-alpine AS builder
WORKDIR /app

COPY build.gradle settings.gradle gradle.lockfile ./
COPY gradle ./gradle

# âœ… --refresh-dependencies uuendab cache'i, aga respekteerib lockfile'i
RUN gradle dependencies --no-daemon --refresh-dependencies

COPY src ./src
RUN gradle bootJar --no-daemon

FROM eclipse-temurin:21-jre-alpine
COPY --from=builder /app/build/libs/*.jar app.jar
CMD ["java", "-jar", "app.jar"]
```

### MÃµÃµdetav mÃµju CI/CD's

**Stsenaarium: GitHub Actions pipeline (10 build'i pÃ¤evas)**

**Ilma reproducible builds'ita:**
```yaml
# .github/workflows/build.yml
jobs:
  build:
    - docker build -t app:latest .  # npm install
    # âŒ Cache miss IGAL build'il (sÃµltuvused muutuvad)
    # Aeg: 3 minutit Ã— 10 = 30 minutit
```

**Reproducible builds'iga:**
```yaml
jobs:
  build:
    - docker build -t app:latest .  # npm ci
    # âœ… Cache hit (package-lock.json ei muutu)
    # Aeg: 30 sekundit Ã— 10 = 5 minutit
```

**Ajakasu:** 25 minutit pÃ¤evas = **2 tundi nÃ¤dalas**!

### Docker Layer Cache CI/CD's

**GitHub Actions nÃ¤ide:**
```yaml
name: Build Docker Image

on: [push]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      # âœ… Cache Docker layers
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Build
        uses: docker/build-push-action@v4
        with:
          context: .
          cache-from: type=gha  # GitHub Actions cache
          cache-to: type=gha,mode=max
          tags: user-service:latest
```

**Tulemus:**
- **Esimene build:** 3 minutit (pole cache'i)
- **JÃ¤rgmised build'id (muutsid koodi):** 30 sekundit (sÃµltuvused cached!)
- **Ajakasu:** 2.5 minutit IGAL build'il

### Reprodutseeritavuse kontrollimine

**Test: Ehita kaks korda, vÃµrdle**
```bash
# Build 1
docker build -t test:v1 .
IMAGE1=$(docker inspect test:v1 --format='{{.Id}}')

# Build 2 (sama kood, sama Dockerfile)
docker build -t test:v2 .
IMAGE2=$(docker inspect test:v2 --format='{{.Id}}')

# VÃµrdle
if [ "$IMAGE1" = "$IMAGE2" ]; then
    echo "âœ… Reproducible! Sama image ID"
else
    echo "âŒ EI OLE reproducible! Erinevad image ID'd"
fi
```

**Reproducible build eeldused:**
- âœ… npm ci (mitte npm install)
- âœ… package-lock.json olemas
- âœ… --only=production (pole dev dependencies)
- âœ… Dockerfile kuupÃ¤evad/ajad ei muutu (nt. `RUN date > /tmp/build-time`)

---

## KokkuvÃµte

| Optimeerimine | Peamine kasu | MÃµÃµdetav mÃµju |
|---------------|--------------|---------------|
| **1. Layer Caching** | Kiiremad rebuildid | 95% kiirem (45s â†’ 2s) |
| **2. Multi-stage** | VÃ¤iksem image | 69% vÃ¤iksem (800MB â†’ 250MB Java) |
| **3. Non-root + Health** | Turvalisus + Monitooring | 80% vÃ¤hem exploit riski, 90s downtime â†’ 0s |
| **4. Proxy tugi** | Portaabelsus | 1 Dockerfile (vs 2), 0% proxy leak |
| **5. Reproducible** | CI/CD kiirus | 25 min â†’ 5 min (80% kiirem pipeline) |

**Kumulatiivne mÃµju (microservices projekt, 10 teenust):**
- **Arendus:** 40 min ootamist pÃ¤evas â†’ 8 min (80% vÃ¤hem)
- **Deployment:** 8GB images â†’ 2.5GB (69% vÃ¤hem)
- **CI/CD:** 2h pipeline â†’ 30 min (75% kiirem)
- **Turvalisus:** Root exploitid 80% â†’ 20% vÃ¤hem

**Tulemus:** Production-ready Docker images! ğŸš€

---

**Viimane uuendus:** 2025-01-25
**TÃ¼Ã¼p:** Koodiselgitus
**Kasutatakse:** Lab 1 (Harjutus 05 - Image Optimeerimine)
